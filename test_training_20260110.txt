Training Documentation
###################################################################################
10.01.2026
################################################################################### 
10 Iterations, 50 Games in parallel, 500 training steps, 32 batch size in the replay buffer (num episodes per training sample
lr of 2e-4, optimizer adamW
###################################################################################
JAX Devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3), CpuDevice(id=4), CpuDevice(id=5), CpuDevice(id=6), CpuDevice(id=7)]
JAX Backend: cpu
(14, 56)
Iteration 1/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(19.166336, dtype=float32), 'r_loss': Array(6.1797824, dtype=float32), 'total_loss': Array(17.563814, dtype=float32), 'v_loss': Array(0.3401946, dtype=float32)}
Step 50, Losses: {'p_loss': Array(16.487522, dtype=float32), 'r_loss': Array(0.02856508, dtype=float32), 'total_loss': Array(9.829755, dtype=float32), 'v_loss': Array(0.36062974, dtype=float32)}
Step 100, Losses: {'p_loss': Array(16.588394, dtype=float32), 'r_loss': Array(0.01444298, dtype=float32), 'total_loss': Array(9.657352, dtype=float32), 'v_loss': Array(0.27094582, dtype=float32)}
Step 150, Losses: {'p_loss': Array(16.557602, dtype=float32), 'r_loss': Array(0.01424985, dtype=float32), 'total_loss': Array(9.616677, dtype=float32), 'v_loss': Array(0.23193073, dtype=float32)}
Step 200, Losses: {'p_loss': Array(15.622858, dtype=float32), 'r_loss': Array(0.01413686, dtype=float32), 'total_loss': Array(9.008378, dtype=float32), 'v_loss': Array(0.26552022, dtype=float32)}
Step 250, Losses: {'p_loss': Array(15.027378, dtype=float32), 'r_loss': Array(0.02995906, dtype=float32), 'total_loss': Array(8.715805, dtype=float32), 'v_loss': Array(0.3124736, dtype=float32)}
Step 300, Losses: {'p_loss': Array(14.565599, dtype=float32), 'r_loss': Array(0.01681602, dtype=float32), 'total_loss': Array(8.357914, dtype=float32), 'v_loss': Array(0.2151686, dtype=float32)}
Step 350, Losses: {'p_loss': Array(13.429615, dtype=float32), 'r_loss': Array(0.01646971, dtype=float32), 'total_loss': Array(7.8182306, dtype=float32), 'v_loss': Array(0.22745287, dtype=float32)}
Step 400, Losses: {'p_loss': Array(13.727918, dtype=float32), 'r_loss': Array(0.01433751, dtype=float32), 'total_loss': Array(7.907768, dtype=float32), 'v_loss': Array(0.20122547, dtype=float32)}
Step 450, Losses: {'p_loss': Array(13.365961, dtype=float32), 'r_loss': Array(0.02755068, dtype=float32), 'total_loss': Array(7.7785835, dtype=float32), 'v_loss': Array(0.27326447, dtype=float32)}

              Iteration 1 completed in 510.60 seconds.
              Game playing + data collection time: 200.82 seconds.
              Training time: 309.78 seconds.

Iteration 2/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(13.414131, dtype=float32), 'r_loss': Array(0.01579051, dtype=float32), 'total_loss': Array(7.6272087, dtype=float32), 'v_loss': Array(0.16255209, dtype=float32)}
Step 50, Losses: {'p_loss': Array(14.249174, dtype=float32), 'r_loss': Array(0.00552449, dtype=float32), 'total_loss': Array(8.214916, dtype=float32), 'v_loss': Array(0.18691228, dtype=float32)}
Step 100, Losses: {'p_loss': Array(13.726705, dtype=float32), 'r_loss': Array(0.00483829, dtype=float32), 'total_loss': Array(7.873906, dtype=float32), 'v_loss': Array(0.18163751, dtype=float32)}
Step 150, Losses: {'p_loss': Array(13.401557, dtype=float32), 'r_loss': Array(0.02223388, dtype=float32), 'total_loss': Array(7.6964254, dtype=float32), 'v_loss': Array(0.25153878, dtype=float32)}
Step 200, Losses: {'p_loss': Array(14.411098, dtype=float32), 'r_loss': Array(0.00699346, dtype=float32), 'total_loss': Array(8.275827, dtype=float32), 'v_loss': Array(0.23444182, dtype=float32)}
Step 250, Losses: {'p_loss': Array(13.878672, dtype=float32), 'r_loss': Array(0.00617621, dtype=float32), 'total_loss': Array(7.9999256, dtype=float32), 'v_loss': Array(0.26479635, dtype=float32)}
Step 300, Losses: {'p_loss': Array(13.063381, dtype=float32), 'r_loss': Array(0.01447602, dtype=float32), 'total_loss': Array(7.599276, dtype=float32), 'v_loss': Array(0.27564055, dtype=float32)}
Step 350, Losses: {'p_loss': Array(13.368576, dtype=float32), 'r_loss': Array(0.00675513, dtype=float32), 'total_loss': Array(7.7122355, dtype=float32), 'v_loss': Array(0.16159774, dtype=float32)}
Step 400, Losses: {'p_loss': Array(13.033691, dtype=float32), 'r_loss': Array(0.03914351, dtype=float32), 'total_loss': Array(7.5565567, dtype=float32), 'v_loss': Array(0.25647384, dtype=float32)}
Step 450, Losses: {'p_loss': Array(12.372509, dtype=float32), 'r_loss': Array(0.05194506, dtype=float32), 'total_loss': Array(7.206544, dtype=float32), 'v_loss': Array(0.23566401, dtype=float32)}

              Iteration 2 completed in 512.55 seconds.
              Game playing + data collection time: 191.40 seconds.
              Training time: 321.15 seconds.

Iteration 3/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(13.422872, dtype=float32), 'r_loss': Array(0.00774895, dtype=float32), 'total_loss': Array(7.6746364, dtype=float32), 'v_loss': Array(0.17374313, dtype=float32)}
Step 50, Losses: {'p_loss': Array(13.130113, dtype=float32), 'r_loss': Array(0.01569229, dtype=float32), 'total_loss': Array(7.5711102, dtype=float32), 'v_loss': Array(0.17645797, dtype=float32)}
Step 100, Losses: {'p_loss': Array(13.150595, dtype=float32), 'r_loss': Array(0.03517097, dtype=float32), 'total_loss': Array(7.6900206, dtype=float32), 'v_loss': Array(0.23241381, dtype=float32)}
Step 150, Losses: {'p_loss': Array(13.44598, dtype=float32), 'r_loss': Array(0.01372, dtype=float32), 'total_loss': Array(7.7366495, dtype=float32), 'v_loss': Array(0.14365292, dtype=float32)}
Step 200, Losses: {'p_loss': Array(13.210487, dtype=float32), 'r_loss': Array(0.00471786, dtype=float32), 'total_loss': Array(7.5961075, dtype=float32), 'v_loss': Array(0.17582428, dtype=float32)}
Step 250, Losses: {'p_loss': Array(13.360527, dtype=float32), 'r_loss': Array(0.01323277, dtype=float32), 'total_loss': Array(7.7389402, dtype=float32), 'v_loss': Array(0.15867156, dtype=float32)}
Step 300, Losses: {'p_loss': Array(12.606622, dtype=float32), 'r_loss': Array(0.03632912, dtype=float32), 'total_loss': Array(7.3010426, dtype=float32), 'v_loss': Array(0.25113463, dtype=float32)}
Step 350, Losses: {'p_loss': Array(12.983001, dtype=float32), 'r_loss': Array(0.00461067, dtype=float32), 'total_loss': Array(7.5016975, dtype=float32), 'v_loss': Array(0.14806458, dtype=float32)}
Step 400, Losses: {'p_loss': Array(12.550854, dtype=float32), 'r_loss': Array(0.01154933, dtype=float32), 'total_loss': Array(7.164128, dtype=float32), 'v_loss': Array(0.17385963, dtype=float32)}
Step 450, Losses: {'p_loss': Array(12.281741, dtype=float32), 'r_loss': Array(0.02492972, dtype=float32), 'total_loss': Array(7.0697803, dtype=float32), 'v_loss': Array(0.171578, dtype=float32)}

              Iteration 3 completed in 510.92 seconds.
              Game playing + data collection time: 175.35 seconds.
              Training time: 335.57 seconds.

Iteration 4/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(13.766119, dtype=float32), 'r_loss': Array(0.0209891, dtype=float32), 'total_loss': Array(7.9719462, dtype=float32), 'v_loss': Array(0.17411266, dtype=float32)}
Step 50, Losses: {'p_loss': Array(12.624868, dtype=float32), 'r_loss': Array(0.03545681, dtype=float32), 'total_loss': Array(7.3385806, dtype=float32), 'v_loss': Array(0.23238988, dtype=float32)}
Step 100, Losses: {'p_loss': Array(13.114532, dtype=float32), 'r_loss': Array(0.01151813, dtype=float32), 'total_loss': Array(7.504545, dtype=float32), 'v_loss': Array(0.20426501, dtype=float32)}
Step 150, Losses: {'p_loss': Array(12.581768, dtype=float32), 'r_loss': Array(0.01247874, dtype=float32), 'total_loss': Array(7.150795, dtype=float32), 'v_loss': Array(0.1482829, dtype=float32)}
Step 200, Losses: {'p_loss': Array(14.101753, dtype=float32), 'r_loss': Array(0.02681428, dtype=float32), 'total_loss': Array(8.120212, dtype=float32), 'v_loss': Array(0.2250421, dtype=float32)}
Step 250, Losses: {'p_loss': Array(13.853428, dtype=float32), 'r_loss': Array(0.0125544, dtype=float32), 'total_loss': Array(7.844049, dtype=float32), 'v_loss': Array(0.19733465, dtype=float32)}
Step 300, Losses: {'p_loss': Array(12.2408695, dtype=float32), 'r_loss': Array(0.01869266, dtype=float32), 'total_loss': Array(7.111002, dtype=float32), 'v_loss': Array(0.20228085, dtype=float32)}
Step 350, Losses: {'p_loss': Array(13.85854, dtype=float32), 'r_loss': Array(0.01357261, dtype=float32), 'total_loss': Array(7.928738, dtype=float32), 'v_loss': Array(0.20237118, dtype=float32)}
Step 400, Losses: {'p_loss': Array(13.14647, dtype=float32), 'r_loss': Array(0.01299445, dtype=float32), 'total_loss': Array(7.5224724, dtype=float32), 'v_loss': Array(0.15767193, dtype=float32)}
Step 450, Losses: {'p_loss': Array(12.465561, dtype=float32), 'r_loss': Array(0.01227033, dtype=float32), 'total_loss': Array(7.210101, dtype=float32), 'v_loss': Array(0.19578522, dtype=float32)}

              Iteration 4 completed in 531.96 seconds.
              Game playing + data collection time: 182.80 seconds.
              Training time: 349.17 seconds.

Iteration 5/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(12.373797, dtype=float32), 'r_loss': Array(0.01237775, dtype=float32), 'total_loss': Array(7.135597, dtype=float32), 'v_loss': Array(0.27456647, dtype=float32)}
Step 50, Losses: {'p_loss': Array(13.391672, dtype=float32), 'r_loss': Array(0.01149954, dtype=float32), 'total_loss': Array(7.6133766, dtype=float32), 'v_loss': Array(0.15322316, dtype=float32)}
Step 100, Losses: {'p_loss': Array(12.589986, dtype=float32), 'r_loss': Array(0.01113318, dtype=float32), 'total_loss': Array(7.1979895, dtype=float32), 'v_loss': Array(0.12386376, dtype=float32)}
Step 150, Losses: {'p_loss': Array(12.055515, dtype=float32), 'r_loss': Array(0.00341994, dtype=float32), 'total_loss': Array(6.9022045, dtype=float32), 'v_loss': Array(0.18786022, dtype=float32)}
Step 200, Losses: {'p_loss': Array(11.892095, dtype=float32), 'r_loss': Array(0.01927975, dtype=float32), 'total_loss': Array(6.859157, dtype=float32), 'v_loss': Array(0.21378572, dtype=float32)}
Step 250, Losses: {'p_loss': Array(12.343452, dtype=float32), 'r_loss': Array(0.0411802, dtype=float32), 'total_loss': Array(7.1877966, dtype=float32), 'v_loss': Array(0.2787887, dtype=float32)}
Step 300, Losses: {'p_loss': Array(12.89517, dtype=float32), 'r_loss': Array(0.02301582, dtype=float32), 'total_loss': Array(7.4739075, dtype=float32), 'v_loss': Array(0.20845744, dtype=float32)}
Step 350, Losses: {'p_loss': Array(13.027443, dtype=float32), 'r_loss': Array(0.00377381, dtype=float32), 'total_loss': Array(7.411429, dtype=float32), 'v_loss': Array(0.13575451, dtype=float32)}
Step 400, Losses: {'p_loss': Array(12.284292, dtype=float32), 'r_loss': Array(0.01141187, dtype=float32), 'total_loss': Array(7.019581, dtype=float32), 'v_loss': Array(0.1658465, dtype=float32)}
Step 450, Losses: {'p_loss': Array(13.148366, dtype=float32), 'r_loss': Array(0.0269601, dtype=float32), 'total_loss': Array(7.5383964, dtype=float32), 'v_loss': Array(0.15549326, dtype=float32)}

              Iteration 5 completed in 568.25 seconds.
              Game playing + data collection time: 204.60 seconds.
              Training time: 363.65 seconds.

Iteration 6/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(12.443232, dtype=float32), 'r_loss': Array(0.00382215, dtype=float32), 'total_loss': Array(7.0778184, dtype=float32), 'v_loss': Array(0.11263163, dtype=float32)}
Step 50, Losses: {'p_loss': Array(12.621105, dtype=float32), 'r_loss': Array(0.00464433, dtype=float32), 'total_loss': Array(7.240451, dtype=float32), 'v_loss': Array(0.1369132, dtype=float32)}
Step 100, Losses: {'p_loss': Array(13.191471, dtype=float32), 'r_loss': Array(0.00347285, dtype=float32), 'total_loss': Array(7.553643, dtype=float32), 'v_loss': Array(0.12313787, dtype=float32)}
Step 150, Losses: {'p_loss': Array(12.903925, dtype=float32), 'r_loss': Array(0.0105779, dtype=float32), 'total_loss': Array(7.389327, dtype=float32), 'v_loss': Array(0.19471934, dtype=float32)}
Step 200, Losses: {'p_loss': Array(12.605646, dtype=float32), 'r_loss': Array(0.00355373, dtype=float32), 'total_loss': Array(7.210067, dtype=float32), 'v_loss': Array(0.11520579, dtype=float32)}
Step 250, Losses: {'p_loss': Array(12.974579, dtype=float32), 'r_loss': Array(0.01963357, dtype=float32), 'total_loss': Array(7.4859505, dtype=float32), 'v_loss': Array(0.1677045, dtype=float32)}
Step 300, Losses: {'p_loss': Array(12.327619, dtype=float32), 'r_loss': Array(0.02662702, dtype=float32), 'total_loss': Array(7.095542, dtype=float32), 'v_loss': Array(0.14706698, dtype=float32)}
Step 350, Losses: {'p_loss': Array(12.706229, dtype=float32), 'r_loss': Array(0.01821259, dtype=float32), 'total_loss': Array(7.255611, dtype=float32), 'v_loss': Array(0.18646938, dtype=float32)}
Step 400, Losses: {'p_loss': Array(13.657043, dtype=float32), 'r_loss': Array(0.01181814, dtype=float32), 'total_loss': Array(7.804905, dtype=float32), 'v_loss': Array(0.1746798, dtype=float32)}
Step 450, Losses: {'p_loss': Array(12.884101, dtype=float32), 'r_loss': Array(0.0199226, dtype=float32), 'total_loss': Array(7.439848, dtype=float32), 'v_loss': Array(0.16987666, dtype=float32)}

              Iteration 6 completed in 572.87 seconds.
              Game playing + data collection time: 204.74 seconds.
              Training time: 368.13 seconds.

Iteration 7/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(12.8074665, dtype=float32), 'r_loss': Array(0.01976728, dtype=float32), 'total_loss': Array(7.349334, dtype=float32), 'v_loss': Array(0.16560277, dtype=float32)}
Step 50, Losses: {'p_loss': Array(12.400358, dtype=float32), 'r_loss': Array(0.00271068, dtype=float32), 'total_loss': Array(7.06097, dtype=float32), 'v_loss': Array(0.1539199, dtype=float32)}
Step 100, Losses: {'p_loss': Array(12.613928, dtype=float32), 'r_loss': Array(0.00334258, dtype=float32), 'total_loss': Array(7.2034245, dtype=float32), 'v_loss': Array(0.14792228, dtype=float32)}
Step 150, Losses: {'p_loss': Array(12.564282, dtype=float32), 'r_loss': Array(0.01220657, dtype=float32), 'total_loss': Array(7.287928, dtype=float32), 'v_loss': Array(0.22015922, dtype=float32)}
Step 200, Losses: {'p_loss': Array(11.909784, dtype=float32), 'r_loss': Array(0.01073732, dtype=float32), 'total_loss': Array(6.915128, dtype=float32), 'v_loss': Array(0.1718378, dtype=float32)}
Step 250, Losses: {'p_loss': Array(12.7662945, dtype=float32), 'r_loss': Array(0.01014916, dtype=float32), 'total_loss': Array(7.374574, dtype=float32), 'v_loss': Array(0.18175793, dtype=float32)}
Step 300, Losses: {'p_loss': Array(13.049665, dtype=float32), 'r_loss': Array(0.01024956, dtype=float32), 'total_loss': Array(7.5361247, dtype=float32), 'v_loss': Array(0.22105633, dtype=float32)}
Step 350, Losses: {'p_loss': Array(12.413919, dtype=float32), 'r_loss': Array(0.01731354, dtype=float32), 'total_loss': Array(7.144309, dtype=float32), 'v_loss': Array(0.18521419, dtype=float32)}
Step 400, Losses: {'p_loss': Array(12.673894, dtype=float32), 'r_loss': Array(0.00411009, dtype=float32), 'total_loss': Array(7.2630095, dtype=float32), 'v_loss': Array(0.14921069, dtype=float32)}
Step 450, Losses: {'p_loss': Array(11.978203, dtype=float32), 'r_loss': Array(0.01093606, dtype=float32), 'total_loss': Array(6.8622675, dtype=float32), 'v_loss': Array(0.15511343, dtype=float32)}

              Iteration 7 completed in 600.57 seconds.
              Game playing + data collection time: 215.08 seconds.
              Training time: 385.49 seconds.

Iteration 8/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(12.934723, dtype=float32), 'r_loss': Array(0.00250033, dtype=float32), 'total_loss': Array(7.347315, dtype=float32), 'v_loss': Array(0.19607252, dtype=float32)}
Step 50, Losses: {'p_loss': Array(12.263857, dtype=float32), 'r_loss': Array(0.01125703, dtype=float32), 'total_loss': Array(7.0592146, dtype=float32), 'v_loss': Array(0.224258, dtype=float32)}
Step 100, Losses: {'p_loss': Array(12.71289, dtype=float32), 'r_loss': Array(0.01804411, dtype=float32), 'total_loss': Array(7.291367, dtype=float32), 'v_loss': Array(0.19164646, dtype=float32)}
Step 150, Losses: {'p_loss': Array(13.533969, dtype=float32), 'r_loss': Array(0.00281564, dtype=float32), 'total_loss': Array(7.7341657, dtype=float32), 'v_loss': Array(0.17623296, dtype=float32)}
Step 200, Losses: {'p_loss': Array(12.692576, dtype=float32), 'r_loss': Array(0.00314249, dtype=float32), 'total_loss': Array(7.311899, dtype=float32), 'v_loss': Array(0.14239381, dtype=float32)}
Step 250, Losses: {'p_loss': Array(12.296033, dtype=float32), 'r_loss': Array(0.00362045, dtype=float32), 'total_loss': Array(7.0054975, dtype=float32), 'v_loss': Array(0.1357437, dtype=float32)}
Step 300, Losses: {'p_loss': Array(12.947172, dtype=float32), 'r_loss': Array(0.00274913, dtype=float32), 'total_loss': Array(7.3564353, dtype=float32), 'v_loss': Array(0.13380384, dtype=float32)}
Step 350, Losses: {'p_loss': Array(12.964461, dtype=float32), 'r_loss': Array(0.01092459, dtype=float32), 'total_loss': Array(7.391269, dtype=float32), 'v_loss': Array(0.12147759, dtype=float32)}
Step 400, Losses: {'p_loss': Array(12.865052, dtype=float32), 'r_loss': Array(0.01090555, dtype=float32), 'total_loss': Array(7.3353047, dtype=float32), 'v_loss': Array(0.14436695, dtype=float32)}
Step 450, Losses: {'p_loss': Array(11.52556, dtype=float32), 'r_loss': Array(0.01007506, dtype=float32), 'total_loss': Array(6.6663256, dtype=float32), 'v_loss': Array(0.17746265, dtype=float32)}

              Iteration 8 completed in 605.65 seconds.
              Game playing + data collection time: 203.57 seconds.
              Training time: 402.08 seconds.

Iteration 9/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(11.374794, dtype=float32), 'r_loss': Array(0.01895786, dtype=float32), 'total_loss': Array(6.5568676, dtype=float32), 'v_loss': Array(0.18717495, dtype=float32)}
Step 50, Losses: {'p_loss': Array(12.846676, dtype=float32), 'r_loss': Array(0.01580207, dtype=float32), 'total_loss': Array(7.357376, dtype=float32), 'v_loss': Array(0.12338749, dtype=float32)}
Step 100, Losses: {'p_loss': Array(11.632132, dtype=float32), 'r_loss': Array(0.01062937, dtype=float32), 'total_loss': Array(6.709109, dtype=float32), 'v_loss': Array(0.13255209, dtype=float32)}
Step 150, Losses: {'p_loss': Array(12.343872, dtype=float32), 'r_loss': Array(0.02370919, dtype=float32), 'total_loss': Array(7.212921, dtype=float32), 'v_loss': Array(0.16677982, dtype=float32)}
Step 200, Losses: {'p_loss': Array(13.283378, dtype=float32), 'r_loss': Array(0.00435502, dtype=float32), 'total_loss': Array(7.608086, dtype=float32), 'v_loss': Array(0.17123444, dtype=float32)}
Step 250, Losses: {'p_loss': Array(10.98432, dtype=float32), 'r_loss': Array(0.00995675, dtype=float32), 'total_loss': Array(6.3645916, dtype=float32), 'v_loss': Array(0.1265971, dtype=float32)}
Step 300, Losses: {'p_loss': Array(12.839974, dtype=float32), 'r_loss': Array(0.00325663, dtype=float32), 'total_loss': Array(7.329015, dtype=float32), 'v_loss': Array(0.11996551, dtype=float32)}
Step 350, Losses: {'p_loss': Array(12.747482, dtype=float32), 'r_loss': Array(0.00939336, dtype=float32), 'total_loss': Array(7.319439, dtype=float32), 'v_loss': Array(0.15367791, dtype=float32)}
Step 400, Losses: {'p_loss': Array(12.392217, dtype=float32), 'r_loss': Array(0.00366085, dtype=float32), 'total_loss': Array(7.0784597, dtype=float32), 'v_loss': Array(0.0969891, dtype=float32)}
Step 450, Losses: {'p_loss': Array(13.26701, dtype=float32), 'r_loss': Array(0.01085564, dtype=float32), 'total_loss': Array(7.578094, dtype=float32), 'v_loss': Array(0.18419647, dtype=float32)}

              Iteration 9 completed in 599.86 seconds.
              Game playing + data collection time: 210.71 seconds.
              Training time: 389.15 seconds.

Iteration 10/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(11.86122, dtype=float32), 'r_loss': Array(0.00990047, dtype=float32), 'total_loss': Array(6.856815, dtype=float32), 'v_loss': Array(0.11550343, dtype=float32)}
Step 50, Losses: {'p_loss': Array(12.607984, dtype=float32), 'r_loss': Array(0.00296152, dtype=float32), 'total_loss': Array(7.1597295, dtype=float32), 'v_loss': Array(0.09482594, dtype=float32)}
Step 100, Losses: {'p_loss': Array(12.742174, dtype=float32), 'r_loss': Array(0.01073651, dtype=float32), 'total_loss': Array(7.2841783, dtype=float32), 'v_loss': Array(0.18882595, dtype=float32)}
Step 150, Losses: {'p_loss': Array(12.844735, dtype=float32), 'r_loss': Array(0.02582398, dtype=float32), 'total_loss': Array(7.3905625, dtype=float32), 'v_loss': Array(0.15946555, dtype=float32)}
Step 200, Losses: {'p_loss': Array(13.383566, dtype=float32), 'r_loss': Array(0.0023335, dtype=float32), 'total_loss': Array(7.601525, dtype=float32), 'v_loss': Array(0.11507678, dtype=float32)}
Step 250, Losses: {'p_loss': Array(12.01742, dtype=float32), 'r_loss': Array(0.03315043, dtype=float32), 'total_loss': Array(6.8794703, dtype=float32), 'v_loss': Array(0.21754038, dtype=float32)}
Step 300, Losses: {'p_loss': Array(12.682713, dtype=float32), 'r_loss': Array(0.01758925, dtype=float32), 'total_loss': Array(7.2722473, dtype=float32), 'v_loss': Array(0.13652527, dtype=float32)}
Step 350, Losses: {'p_loss': Array(12.405508, dtype=float32), 'r_loss': Array(0.03762982, dtype=float32), 'total_loss': Array(7.2318287, dtype=float32), 'v_loss': Array(0.19613175, dtype=float32)}
Step 400, Losses: {'p_loss': Array(12.001972, dtype=float32), 'r_loss': Array(0.01019536, dtype=float32), 'total_loss': Array(6.9244585, dtype=float32), 'v_loss': Array(0.09599443, dtype=float32)}
Step 450, Losses: {'p_loss': Array(11.853552, dtype=float32), 'r_loss': Array(0.00341585, dtype=float32), 'total_loss': Array(6.756319, dtype=float32), 'v_loss': Array(0.11364283, dtype=float32)}

              Iteration 10 completed in 566.72 seconds.
              Game playing + data collection time: 197.30 seconds.
              Training time: 369.42 seconds.
###################################################################################
Ãœberarbeitetes reward system
###################################################################################
(14, 56)
Iteration 1/10
Saving collected games to replay buffer...
Training on collected data...
Step 0, Losses: {'p_loss': Array(20.6984, dtype=float32), 'total_loss': Array(7.3236146, dtype=float32), 'v_loss': Array(1.2070838, dtype=float32)}
Step 50, Losses: {'p_loss': Array(17.285343, dtype=float32), 'total_loss': Array(5.958888, dtype=float32), 'v_loss': Array(1.2462196, dtype=float32)}
Step 100, Losses: {'p_loss': Array(16.146381, dtype=float32), 'total_loss': Array(5.6978903, dtype=float32), 'v_loss': Array(1.3657539, dtype=float32)}
Step 150, Losses: {'p_loss': Array(14.257483, dtype=float32), 'total_loss': Array(4.8848815, dtype=float32), 'v_loss': Array(0.9617032, dtype=float32)}
Step 200, Losses: {'p_loss': Array(14.956999, dtype=float32), 'total_loss': Array(5.0798717, dtype=float32), 'v_loss': Array(0.90677834, dtype=float32)}
Step 250, Losses: {'p_loss': Array(13.659849, dtype=float32), 'total_loss': Array(4.6717386, dtype=float32), 'v_loss': Array(1.1470133, dtype=float32)}
Step 300, Losses: {'p_loss': Array(13.749333, dtype=float32), 'total_loss': Array(4.745285, dtype=float32), 'v_loss': Array(1.6442528, dtype=float32)}
Step 350, Losses: {'p_loss': Array(13.183966, dtype=float32), 'total_loss': Array(4.366772, dtype=float32), 'v_loss': Array(0.57036895, dtype=float32)}
Step 400, Losses: {'p_loss': Array(14.141167, dtype=float32), 'total_loss': Array(4.8113937, dtype=float32), 'v_loss': Array(0.9212504, dtype=float32)}
Step 450, Losses: {'p_loss': Array(14.051028, dtype=float32), 'total_loss': Array(4.771066, dtype=float32), 'v_loss': Array(0.8956215, dtype=float32)}

              Iteration 1 completed in 420.66 seconds.
              Game playing + data collection time: 226.35 seconds.
              Training time: 194.31 seconds.

Iteration 2/10
###################################################################################